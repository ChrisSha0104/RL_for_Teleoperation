# RL_for_Teleoperation

### Overview
This project focuses on developing a **teleoperation interface** designed to enhance the quality of data collected during imitation learning for rigid-body dynamics tasks. The system integrates a **residual reinforcement learning (RL) policy** to refine operator inputs and improve the quality of demonstrations in real-time.

### Key Features
- **Residual Policy Integration**: A residual RL policy is added to assist the operator by fine-tuning their actions, reducing noise, and ensuring more accurate demonstrations.
- **Real-Time Processing**: The interface operates in real-time, supporting dynamic and highly responsive tasks.
- **Target Application**: Specifically tailored for challenging rigid-body dynamics tasks where high quality expert demonstrations are difficult to obtain.

### Potential Impact
- Improved data quality for imitation learning pipelines.
- Enhanced operator efficiency and reduced cognitive load during teleoperation.

### Status
- **Current Stage**: Development phase, with ongoing testing in simulated environments.
- **Next Steps**: Finalizing experiments and preparing for submission to CoRL 2025.
